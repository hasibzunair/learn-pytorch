{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified from https://github.com/kuangliu/pytorch-cifar/blob/master/main.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (12): ReLU(inplace=True)\n",
      "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (16): ReLU(inplace=True)\n",
      "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (19): ReLU(inplace=True)\n",
      "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (25): ReLU(inplace=True)\n",
      "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (32): ReLU(inplace=True)\n",
      "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (35): ReLU(inplace=True)\n",
      "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (38): ReLU(inplace=True)\n",
      "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (42): ReLU(inplace=True)\n",
      "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (45): ReLU(inplace=True)\n",
      "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (48): ReLU(inplace=True)\n",
      "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (51): ReLU(inplace=True)\n",
      "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (53): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "    )\n",
      "    (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = None\n",
    "net = VGG('VGG19')\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "        if not batch_idx % 50:\n",
    "                print(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "                \n",
    "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            #% (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "def test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            if not batch_idx % 50:\n",
    "                print(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                    % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "            #progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                #% (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving at {}%'.format(acc))\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "0 391 Loss: 2.604 | Acc: 10.156% (13/128)\n",
      "50 391 Loss: 3.701 | Acc: 10.202% (666/6528)\n",
      "100 391 Loss: 3.126 | Acc: 10.620% (1373/12928)\n",
      "150 391 Loss: 2.875 | Acc: 10.782% (2084/19328)\n",
      "200 391 Loss: 2.739 | Acc: 10.735% (2762/25728)\n",
      "250 391 Loss: 2.653 | Acc: 10.657% (3424/32128)\n",
      "300 391 Loss: 2.593 | Acc: 10.631% (4096/38528)\n",
      "350 391 Loss: 2.550 | Acc: 10.635% (4778/44928)\n",
      "0 100 Loss: 2.235 | Acc: 13.000% (13/100)\n",
      "50 100 Loss: 2.281 | Acc: 11.765% (600/5100)\n",
      "Saving at 12.11%\n",
      "\n",
      "Epoch: 1\n",
      "0 391 Loss: 2.300 | Acc: 7.031% (9/128)\n",
      "50 391 Loss: 2.281 | Acc: 11.504% (751/6528)\n",
      "100 391 Loss: 2.272 | Acc: 12.260% (1585/12928)\n",
      "150 391 Loss: 2.260 | Acc: 13.266% (2564/19328)\n",
      "200 391 Loss: 2.227 | Acc: 14.513% (3734/25728)\n",
      "250 391 Loss: 2.198 | Acc: 15.466% (4969/32128)\n",
      "300 391 Loss: 2.165 | Acc: 16.302% (6281/38528)\n",
      "350 391 Loss: 2.137 | Acc: 16.920% (7602/44928)\n",
      "0 100 Loss: 1.888 | Acc: 21.000% (21/100)\n",
      "50 100 Loss: 1.939 | Acc: 23.078% (1177/5100)\n",
      "Saving at 22.62%\n",
      "\n",
      "Epoch: 2\n",
      "0 391 Loss: 1.870 | Acc: 21.094% (27/128)\n",
      "50 391 Loss: 1.937 | Acc: 21.706% (1417/6528)\n",
      "100 391 Loss: 1.931 | Acc: 22.084% (2855/12928)\n",
      "150 391 Loss: 1.914 | Acc: 22.811% (4409/19328)\n",
      "200 391 Loss: 1.907 | Acc: 23.298% (5994/25728)\n",
      "250 391 Loss: 1.900 | Acc: 23.976% (7703/32128)\n",
      "300 391 Loss: 1.894 | Acc: 24.263% (9348/38528)\n",
      "350 391 Loss: 1.889 | Acc: 24.631% (11066/44928)\n",
      "0 100 Loss: 1.793 | Acc: 32.000% (32/100)\n",
      "50 100 Loss: 1.807 | Acc: 28.059% (1431/5100)\n",
      "Saving at 27.87%\n",
      "\n",
      "Epoch: 3\n",
      "0 391 Loss: 1.864 | Acc: 25.781% (33/128)\n",
      "50 391 Loss: 1.815 | Acc: 28.156% (1838/6528)\n",
      "100 391 Loss: 1.798 | Acc: 28.287% (3657/12928)\n",
      "150 391 Loss: 1.783 | Acc: 28.818% (5570/19328)\n",
      "200 391 Loss: 1.769 | Acc: 29.653% (7629/25728)\n",
      "250 391 Loss: 1.753 | Acc: 30.357% (9753/32128)\n",
      "300 391 Loss: 1.732 | Acc: 31.419% (12105/38528)\n",
      "350 391 Loss: 1.712 | Acc: 32.472% (14589/44928)\n",
      "0 100 Loss: 1.602 | Acc: 43.000% (43/100)\n",
      "50 100 Loss: 1.660 | Acc: 38.608% (1969/5100)\n",
      "Saving at 38.15%\n",
      "\n",
      "Epoch: 4\n",
      "0 391 Loss: 1.564 | Acc: 46.094% (59/128)\n",
      "50 391 Loss: 1.537 | Acc: 42.065% (2746/6528)\n",
      "100 391 Loss: 1.528 | Acc: 42.025% (5433/12928)\n",
      "150 391 Loss: 1.506 | Acc: 42.788% (8270/19328)\n",
      "200 391 Loss: 1.487 | Acc: 43.412% (11169/25728)\n",
      "250 391 Loss: 1.466 | Acc: 44.475% (14289/32128)\n",
      "300 391 Loss: 1.458 | Acc: 45.032% (17350/38528)\n",
      "350 391 Loss: 1.448 | Acc: 45.531% (20456/44928)\n",
      "0 100 Loss: 1.299 | Acc: 54.000% (54/100)\n",
      "50 100 Loss: 1.341 | Acc: 50.706% (2586/5100)\n",
      "Saving at 50.73%\n",
      "\n",
      "Epoch: 5\n",
      "0 391 Loss: 1.232 | Acc: 52.344% (67/128)\n",
      "50 391 Loss: 1.297 | Acc: 53.676% (3504/6528)\n",
      "100 391 Loss: 1.296 | Acc: 53.465% (6912/12928)\n",
      "150 391 Loss: 1.285 | Acc: 54.139% (10464/19328)\n",
      "200 391 Loss: 1.270 | Acc: 54.645% (14059/25728)\n",
      "250 391 Loss: 1.246 | Acc: 55.400% (17799/32128)\n",
      "300 391 Loss: 1.232 | Acc: 56.066% (21601/38528)\n",
      "350 391 Loss: 1.219 | Acc: 56.548% (25406/44928)\n",
      "0 100 Loss: 1.102 | Acc: 60.000% (60/100)\n",
      "50 100 Loss: 1.086 | Acc: 61.804% (3152/5100)\n",
      "Saving at 61.39%\n",
      "\n",
      "Epoch: 6\n",
      "0 391 Loss: 0.981 | Acc: 62.500% (80/128)\n",
      "50 391 Loss: 1.080 | Acc: 61.994% (4047/6528)\n",
      "100 391 Loss: 1.067 | Acc: 62.276% (8051/12928)\n",
      "150 391 Loss: 1.062 | Acc: 62.453% (12071/19328)\n",
      "200 391 Loss: 1.061 | Acc: 62.624% (16112/25728)\n",
      "250 391 Loss: 1.049 | Acc: 63.054% (20258/32128)\n",
      "300 391 Loss: 1.043 | Acc: 63.351% (24408/38528)\n",
      "350 391 Loss: 1.035 | Acc: 63.595% (28572/44928)\n",
      "0 100 Loss: 1.671 | Acc: 48.000% (48/100)\n",
      "50 100 Loss: 1.730 | Acc: 47.196% (2407/5100)\n",
      "\n",
      "Epoch: 7\n",
      "0 391 Loss: 0.930 | Acc: 70.312% (90/128)\n",
      "50 391 Loss: 0.963 | Acc: 66.682% (4353/6528)\n",
      "100 391 Loss: 0.946 | Acc: 67.265% (8696/12928)\n",
      "150 391 Loss: 0.941 | Acc: 67.596% (13065/19328)\n",
      "200 391 Loss: 0.937 | Acc: 67.634% (17401/25728)\n",
      "250 391 Loss: 0.931 | Acc: 67.816% (21788/32128)\n",
      "300 391 Loss: 0.927 | Acc: 67.935% (26174/38528)\n",
      "350 391 Loss: 0.921 | Acc: 68.234% (30656/44928)\n",
      "0 100 Loss: 1.250 | Acc: 59.000% (59/100)\n",
      "50 100 Loss: 1.246 | Acc: 60.216% (3071/5100)\n",
      "\n",
      "Epoch: 8\n",
      "0 391 Loss: 0.891 | Acc: 71.094% (91/128)\n",
      "50 391 Loss: 0.871 | Acc: 70.987% (4634/6528)\n",
      "100 391 Loss: 0.868 | Acc: 70.746% (9146/12928)\n",
      "150 391 Loss: 0.863 | Acc: 70.887% (13701/19328)\n",
      "200 391 Loss: 0.853 | Acc: 71.183% (18314/25728)\n",
      "250 391 Loss: 0.850 | Acc: 71.290% (22904/32128)\n",
      "300 391 Loss: 0.848 | Acc: 71.377% (27500/38528)\n",
      "350 391 Loss: 0.843 | Acc: 71.626% (32180/44928)\n",
      "0 100 Loss: 1.331 | Acc: 57.000% (57/100)\n",
      "50 100 Loss: 1.473 | Acc: 59.294% (3024/5100)\n",
      "\n",
      "Epoch: 9\n",
      "0 391 Loss: 0.904 | Acc: 67.969% (87/128)\n",
      "50 391 Loss: 0.773 | Acc: 74.510% (4864/6528)\n",
      "100 391 Loss: 0.784 | Acc: 74.203% (9593/12928)\n",
      "150 391 Loss: 0.776 | Acc: 74.302% (14361/19328)\n",
      "200 391 Loss: 0.785 | Acc: 74.005% (19040/25728)\n",
      "250 391 Loss: 0.779 | Acc: 74.278% (23864/32128)\n",
      "300 391 Loss: 0.773 | Acc: 74.442% (28681/38528)\n",
      "350 391 Loss: 0.770 | Acc: 74.617% (33524/44928)\n",
      "0 100 Loss: 1.504 | Acc: 53.000% (53/100)\n",
      "50 100 Loss: 1.371 | Acc: 57.275% (2921/5100)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace=True)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace=True)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace=True)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace=True)\n",
       "      (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (38): ReLU(inplace=True)\n",
       "      (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace=True)\n",
       "      (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (45): ReLU(inplace=True)\n",
       "      (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (48): ReLU(inplace=True)\n",
       "      (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (51): ReLU(inplace=True)\n",
       "      (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (53): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "    )\n",
       "    (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"checkpoint/ckpt.pth\")['net'])\n",
    "\n",
    "# Send model to GPU\n",
    "if device:\n",
    "    net.cuda()\n",
    "    \n",
    "net.eval()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(testloader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([100]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n",
       "        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n",
       "        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3, 6, 2, 1, 2, 3, 7, 2, 6,\n",
       "        8, 8, 0, 2, 9, 3, 3, 8, 8, 1, 1, 7, 2, 5, 2, 7, 8, 9, 0, 3, 8, 6, 4, 6,\n",
       "        6, 0, 0, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = net(features.to(device))\n",
    "print(logits.shape)\n",
    "_, predicted_labels = torch.max(logits, 1)\n",
    "predicted_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 8, 8, 8, 6, 6, 1, 2, 3, 9, 3, 9, 4, 5, 8, 8, 5, 3, 8, 6, 9, 0, 0, 9,\n",
       "        4, 4, 4, 2, 9, 6, 6, 5, 6, 2, 9, 3, 4, 9, 9, 5, 0, 6, 3, 6, 0, 9, 3, 9,\n",
       "        4, 2, 9, 8, 3, 3, 8, 8, 4, 3, 3, 3, 7, 3, 6, 3, 6, 6, 8, 0, 3, 7, 2, 6,\n",
       "        8, 8, 8, 2, 9, 3, 5, 8, 8, 8, 1, 5, 5, 9, 3, 3, 8, 9, 0, 6, 8, 6, 4, 6,\n",
       "        6, 0, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predicted_labels.cpu().data.numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = targets.cpu().data.numpy()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "accuracy_score(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.57      0.40      0.47        10\n",
      "         car       1.00      0.33      0.50         6\n",
      "        bird       0.29      0.25      0.27         8\n",
      "         cat       0.42      0.80      0.55        10\n",
      "        deer       0.38      0.43      0.40         7\n",
      "         dog       0.43      0.38      0.40         8\n",
      "        frog       0.81      0.81      0.81        16\n",
      "       horse       1.00      0.18      0.31        11\n",
      "        ship       0.72      1.00      0.84        13\n",
      "       truck       0.71      0.91      0.80        11\n",
      "\n",
      "    accuracy                           0.60       100\n",
      "   macro avg       0.63      0.55      0.53       100\n",
      "weighted avg       0.66      0.60      0.57       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "target_names = list(classes)\n",
    "print(classification_report(labels, preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits = model(features)\n",
    "        _, predicted_labels = torch.max(logits, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 61.39%\n"
     ]
    }
   ],
   "source": [
    "# Compute test accuracy\n",
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(net, testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
